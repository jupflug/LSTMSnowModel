{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea480b98-56d9-406a-b62e-412b451af3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a31d4eb-e383-4cbc-816c-cff6e59da89f",
   "metadata": {},
   "source": [
    "### Define user parameters and definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771aaa8b-6be1-4493-87ef-4e7a32a82682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory containing the trained modelfiles\n",
    "model_direc = '/direcc/jpflug/ML_layers/WUS_tiles/temp/trial8/'\n",
    "\n",
    "# in the instance when multiple model types exist, provide wildcard reader to read in correct set\n",
    "model_prefix = 'linear_bestoutput*.hdf5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3c206a-e199-47da-b5b7-92d8ba1fe0cf",
   "metadata": {},
   "source": [
    "### Script functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5aaa6-ca23-442d-8308-26ace6914ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensure this is the same loss function used for the model training\n",
    "# 1_trainModel.ipynb\n",
    "def default_mean_squared_error(y_true, y_pred):\n",
    "    loss = tf.square(y_true - y_pred)\n",
    "    return tf.reduce_mean(loss)\n",
    "    \n",
    "# Register custom loss functions\n",
    "get_custom_objects().update({\n",
    "    'default_mean_squared_error': default_mean_squared_error\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24535fb-ee2a-4f94-94be-c3f4b9bfe6d5",
   "metadata": {},
   "source": [
    "### Read in and prepare the model data for predictions\n",
    "#### Please review previous scripts for more detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b9fb3d-74d0-40b8-b53f-d46a3817bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ML models\n",
    "models = sorted(glob.glob(model_direc+model_prefix))\n",
    "\n",
    "# load the normalization\n",
    "# order of form: SWEmax,SWEanom_min,SWEanom_max,min_T,max_T,max_P\n",
    "norm_bounds = np.load(norm_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bf5988-c7a7-45c7-992c-5b6d23c88cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data using preferred approach \n",
    "# Please review 0_prepareData and 1_trainModel for data prep examples\n",
    "# required data to run the model: dsSCF, SCFaccum, dsT, dsP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09eed4b-c0ec-4df1-9b33-1c5145fbc8f6",
   "metadata": {},
   "source": [
    "### Run the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca672b3-fd77-46fe-bd67-d307bfa24199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through the selected models to run\n",
    "for mod_name in models:\n",
    "    model = load_model(mod_name,\n",
    "                       custom_objects={'output_mse1': default_mean_squared_error, 'output_mse3': default_mean_squared_error})\n",
    "    swe = model.predict([dsSCF,SCFaccum,dsT,dsP])\n",
    "    # convert from normalized space\n",
    "    # default LSTM output\n",
    "    swe[0] = swe[0].T*norm_bounds[0]\n",
    "    # melt-corrected LSTM output\n",
    "    swe[1] = swe[1].T*norm_bounds[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pangeo",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
